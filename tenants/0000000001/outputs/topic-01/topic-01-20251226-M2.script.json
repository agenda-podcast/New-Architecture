{
  "title": "Global cost of living and rising prices - M2",
  "duration_sec": 0,
  "segments": [
    {
      "chapter": 1,
      "title": "Medium",
      "start_time": 0,
      "duration": 0,
      "dialogue": [
        {
          "speaker": "A",
          "text": "Let's talk about what this AI regulation actually means in practice."
        },
        {
          "speaker": "B",
          "text": "Right, because the devil is in the details. These aren't just guidelines—they're enforceable requirements with real teeth."
        },
        {
          "speaker": "A",
          "text": "So what are the specific requirements?"
        },
        {
          "speaker": "B",
          "text": "Three main categories. First, transparency—companies must disclose how their models work, what data they use, and what their limitations are."
        },
        {
          "speaker": "A",
          "text": "That's a big change. A lot of this has been proprietary until now."
        },
        {
          "speaker": "B",
          "text": "Exactly. Second requirement is regular safety audits. Independent third parties will test these systems for bias, accuracy, and potential harms."
        },
        {
          "speaker": "A",
          "text": "How often?"
        },
        {
          "speaker": "B",
          "text": "Annually for most companies, quarterly for high-risk applications like healthcare or financial services."
        },
        {
          "speaker": "A",
          "text": "That's intensive. And expensive."
        },
        {
          "speaker": "B",
          "text": "Very. Which is why smaller companies are concerned. But it's also necessary—we've seen too many incidents of AI systems going wrong."
        },
        {
          "speaker": "A",
          "text": "What about enforcement? Who's making sure companies comply?"
        },
        {
          "speaker": "B",
          "text": "The Tech Policy Institute gets enforcement powers. They can issue fines up to 4% of global revenue for serious violations."
        },
        {
          "speaker": "A",
          "text": "Wow, that's significant."
        },
        {
          "speaker": "B",
          "text": "It's modeled after GDPR's enforcement structure, which has been pretty effective in Europe."
        },
        {
          "speaker": "A",
          "text": "So what does this mean for innovation? Are we going to see a slowdown?"
        },
        {
          "speaker": "B",
          "text": "Not necessarily. In fact, some argue this could accelerate responsible innovation. When everyone's playing by the same rules, it creates a level playing field."
        },
        {
          "speaker": "A",
          "text": "That's an interesting perspective."
        },
        {
          "speaker": "B",
          "text": "Yeah, and historically, we've seen that regulation can actually increase consumer trust, which grows the market overall."
        },
        {
          "speaker": "A",
          "text": "So it's not just about restrictions—it's about building sustainable growth."
        },
        {
          "speaker": "B",
          "text": "Exactly. The goal is to prevent a major AI disaster that would tank public trust and hurt everyone."
        },
        {
          "speaker": "A",
          "text": "That makes sense. Prevention is better than damage control."
        },
        {
          "speaker": "B",
          "text": "Right. And the industry mostly gets this. They'd rather have clear rules now than face a backlash later."
        },
        {
          "speaker": "A",
          "text": "Alright, we'll keep tracking this story. Make sure to follow us for updates as the implementation details come out! [WORD_COUNT=380]"
        },
        {
          "speaker": "A",
          "text": "Let's dive even deeper into this topic, because there's so much more to explore here."
        },
        {
          "speaker": "B",
          "text": "Absolutely. We've covered the basics, but the implications and details are really worth examining more closely."
        },
        {
          "speaker": "A",
          "text": "Building on that, Let's talk about what this AI regulation actually means in practice."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Right, because the devil is in the details. These aren't just guidelines—they're enforceable requirements with real teeth."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Three main categories. First, transparency—companies must disclose how their models work, what data they use, and what their limitations are."
        },
        {
          "speaker": "A",
          "text": "Building on that, That's a big change. A lot of this has been proprietary until now."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Exactly. Second requirement is regular safety audits. Independent third parties will test these systems for bias, accuracy, and potential harms."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Annually for most companies, quarterly for high-risk applications like healthcare or financial services."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Very. Which is why smaller companies are concerned. But it's also necessary—we've seen too many incidents of AI systems going wrong."
        },
        {
          "speaker": "B",
          "text": "To elaborate, The Tech Policy Institute gets enforcement powers. They can issue fines up to 4% of global revenue for serious violations."
        },
        {
          "speaker": "B",
          "text": "To elaborate, It's modeled after GDPR's enforcement structure, which has been pretty effective in Europe."
        },
        {
          "speaker": "A",
          "text": "Building on that, So what does this mean for innovation? Are we going to see a slowdown?"
        },
        {
          "speaker": "B",
          "text": "To elaborate, Not necessarily. In fact, some argue this could accelerate responsible innovation. When everyone's playing by the same rules, it creates a level playing field."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Yeah, and historically, we've seen that regulation can actually increase consumer trust, which grows the market overall."
        },
        {
          "speaker": "A",
          "text": "Building on that, So it's not just about restrictions—it's about building sustainable growth."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Exactly. The goal is to prevent a major AI disaster that would tank public trust and hurt everyone."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Right. And the industry mostly gets this. They'd rather have clear rules now than face a backlash later."
        },
        {
          "speaker": "A",
          "text": "Building on that, Alright, we'll keep tracking this story. Make sure to follow us for updates as the implementation details come out!"
        },
        {
          "speaker": "A",
          "text": "Let's explore another important aspect of this."
        },
        {
          "speaker": "A",
          "text": "Let's talk about what this AI regulation actually means in practice."
        },
        {
          "speaker": "B",
          "text": "Right, because the devil is in the details. These aren't just guidelines—they're enforceable requirements with real teeth."
        },
        {
          "speaker": "A",
          "text": "So what are the specific requirements?"
        },
        {
          "speaker": "B",
          "text": "Three main categories. First, transparency—companies must disclose how their models work, what data they use, and what their limitations are."
        },
        {
          "speaker": "A",
          "text": "That's a big change. A lot of this has been proprietary until now."
        },
        {
          "speaker": "B",
          "text": "Exactly. Second requirement is regular safety audits. Independent third parties will test these systems for bias, accuracy, and potential harms."
        },
        {
          "speaker": "A",
          "text": "How often?"
        },
        {
          "speaker": "B",
          "text": "Annually for most companies, quarterly for high-risk applications like healthcare or financial services."
        },
        {
          "speaker": "A",
          "text": "That's intensive. And expensive."
        },
        {
          "speaker": "B",
          "text": "Very. Which is why smaller companies are concerned. But it's also necessary—we've seen too many incidents of AI systems going wrong."
        },
        {
          "speaker": "A",
          "text": "What about enforcement? Who's making sure companies comply?"
        },
        {
          "speaker": "B",
          "text": "The Tech Policy Institute gets enforcement powers. They can issue fines up to 4% of global revenue for serious violations."
        },
        {
          "speaker": "A",
          "text": "Wow, that's significant."
        },
        {
          "speaker": "B",
          "text": "It's modeled after GDPR's enforcement structure, which has been pretty effective in Europe."
        },
        {
          "speaker": "A",
          "text": "So what does this mean for innovation? Are we going to see a slowdown?"
        },
        {
          "speaker": "B",
          "text": "Not necessarily. In fact, some argue this could accelerate responsible innovation. When everyone's playing by the same rules, it creates a level playing field."
        },
        {
          "speaker": "A",
          "text": "That's an interesting perspective."
        },
        {
          "speaker": "B",
          "text": "Yeah, and historically, we've seen that regulation can actually increase consumer trust, which grows the market overall."
        },
        {
          "speaker": "A",
          "text": "So it's not just about restrictions—it's about building sustainable growth."
        },
        {
          "speaker": "B",
          "text": "Exactly. The goal is to prevent a major AI disaster that would tank public trust and hurt everyone."
        },
        {
          "speaker": "A",
          "text": "That makes sense. Prevention is better than damage control."
        },
        {
          "speaker": "B",
          "text": "Right. And the industry mostly gets this. They'd rather have clear rules now than face a backlash later."
        },
        {
          "speaker": "A",
          "text": "Alright, we'll keep tracking this story. Make sure to follow us for updates as the implementation details come out! [WORD_COUNT=380]"
        },
        {
          "speaker": "A",
          "text": "Let's dive even deeper into this topic, because there's so much more to explore here."
        },
        {
          "speaker": "B",
          "text": "Absolutely. We've covered the basics, but the implications and details are really worth examining more closely."
        },
        {
          "speaker": "A",
          "text": "Building on that, Let's talk about what this AI regulation actually means in practice."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Right, because the devil is in the details. These aren't just guidelines—they're enforceable requirements with real teeth."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Three main categories. First, transparency—companies must disclose how their models work, what data they use, and what their limitations are."
        },
        {
          "speaker": "A",
          "text": "Building on that, That's a big change. A lot of this has been proprietary until now."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Exactly. Second requirement is regular safety audits. Independent third parties will test these systems for bias, accuracy, and potential harms."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Annually for most companies, quarterly for high-risk applications like healthcare or financial services."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Very. Which is why smaller companies are concerned. But it's also necessary—we've seen too many incidents of AI systems going wrong."
        },
        {
          "speaker": "B",
          "text": "To elaborate, The Tech Policy Institute gets enforcement powers. They can issue fines up to 4% of global revenue for serious violations."
        },
        {
          "speaker": "B",
          "text": "To elaborate, It's modeled after GDPR's enforcement structure, which has been pretty effective in Europe."
        },
        {
          "speaker": "A",
          "text": "Building on that, So what does this mean for innovation? Are we going to see a slowdown?"
        },
        {
          "speaker": "B",
          "text": "To elaborate, Not necessarily. In fact, some argue this could accelerate responsible innovation. When everyone's playing by the same rules, it creates a level playing field."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Yeah, and historically, we've seen that regulation can actually increase consumer trust, which grows the market overall."
        },
        {
          "speaker": "A",
          "text": "Building on that, So it's not just about restrictions—it's about building sustainable growth."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Exactly. The goal is to prevent a major AI disaster that would tank public trust and hurt everyone."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Right. And the industry mostly gets this. They'd rather have clear rules now than face a backlash later."
        },
        {
          "speaker": "A",
          "text": "Building on that, Alright, we'll keep tracking this story. Make sure to follow us for updates as the implementation details come out!"
        },
        {
          "speaker": "A",
          "text": "Let's explore another important aspect of this."
        },
        {
          "speaker": "A",
          "text": "Let's talk about what this AI regulation actually means in practice."
        },
        {
          "speaker": "B",
          "text": "Right, because the devil is in the details. These aren't just guidelines—they're enforceable requirements with real teeth."
        },
        {
          "speaker": "A",
          "text": "So what are the specific requirements?"
        },
        {
          "speaker": "B",
          "text": "Three main categories. First, transparency—companies must disclose how their models work, what data they use, and what their limitations are."
        },
        {
          "speaker": "A",
          "text": "That's a big change. A lot of this has been proprietary until now."
        },
        {
          "speaker": "B",
          "text": "Exactly. Second requirement is regular safety audits. Independent third parties will test these systems for bias, accuracy, and potential harms."
        },
        {
          "speaker": "A",
          "text": "How often?"
        },
        {
          "speaker": "B",
          "text": "Annually for most companies, quarterly for high-risk applications like healthcare or financial services."
        },
        {
          "speaker": "A",
          "text": "That's intensive. And expensive."
        },
        {
          "speaker": "B",
          "text": "Very. Which is why smaller companies are concerned. But it's also necessary—we've seen too many incidents of AI systems going wrong."
        },
        {
          "speaker": "A",
          "text": "What about enforcement? Who's making sure companies comply?"
        },
        {
          "speaker": "B",
          "text": "The Tech Policy Institute gets enforcement powers. They can issue fines up to 4% of global revenue for serious violations."
        },
        {
          "speaker": "A",
          "text": "Wow, that's significant."
        },
        {
          "speaker": "B",
          "text": "It's modeled after GDPR's enforcement structure, which has been pretty effective in Europe."
        },
        {
          "speaker": "A",
          "text": "So what does this mean for innovation? Are we going to see a slowdown?"
        },
        {
          "speaker": "B",
          "text": "Not necessarily. In fact, some argue this could accelerate responsible innovation. When everyone's playing by the same rules, it creates a level playing field."
        },
        {
          "speaker": "A",
          "text": "That's an interesting perspective."
        },
        {
          "speaker": "B",
          "text": "Yeah, and historically, we've seen that regulation can actually increase consumer trust, which grows the market overall."
        },
        {
          "speaker": "A",
          "text": "So it's not just about restrictions—it's about building sustainable growth."
        },
        {
          "speaker": "B",
          "text": "Exactly. The goal is to prevent a major AI disaster that would tank public trust and hurt everyone."
        },
        {
          "speaker": "A",
          "text": "That makes sense. Prevention is better than damage control."
        },
        {
          "speaker": "B",
          "text": "Right. And the industry mostly gets this. They'd rather have clear rules now than face a backlash later."
        },
        {
          "speaker": "A",
          "text": "Alright, we'll keep tracking this story. Make sure to follow us for updates as the implementation details come out! [WORD_COUNT=380]"
        },
        {
          "speaker": "A",
          "text": "Let's dive even deeper into this topic, because there's so much more to explore here."
        },
        {
          "speaker": "B",
          "text": "Absolutely. We've covered the basics, but the implications and details are really worth examining more closely."
        },
        {
          "speaker": "A",
          "text": "Building on that, Let's talk about what this AI regulation actually means in practice."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Right, because the devil is in the details. These aren't just guidelines—they're enforceable requirements with real teeth."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Three main categories. First, transparency—companies must disclose how their models work, what data they use, and what their limitations are."
        },
        {
          "speaker": "A",
          "text": "Building on that, That's a big change. A lot of this has been proprietary until now."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Exactly. Second requirement is regular safety audits. Independent third parties will test these systems for bias, accuracy, and potential harms."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Annually for most companies, quarterly for high-risk applications like healthcare or financial services."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Very. Which is why smaller companies are concerned. But it's also necessary—we've seen too many incidents of AI systems going wrong."
        },
        {
          "speaker": "B",
          "text": "To elaborate, The Tech Policy Institute gets enforcement powers. They can issue fines up to 4% of global revenue for serious violations."
        },
        {
          "speaker": "B",
          "text": "To elaborate, It's modeled after GDPR's enforcement structure, which has been pretty effective in Europe."
        },
        {
          "speaker": "A",
          "text": "Building on that, So what does this mean for innovation? Are we going to see a slowdown?"
        },
        {
          "speaker": "B",
          "text": "To elaborate, Not necessarily. In fact, some argue this could accelerate responsible innovation. When everyone's playing by the same rules, it creates a level playing field."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Yeah, and historically, we've seen that regulation can actually increase consumer trust, which grows the market overall."
        },
        {
          "speaker": "A",
          "text": "Building on that, So it's not just about restrictions—it's about building sustainable growth."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Exactly. The goal is to prevent a major AI disaster that would tank public trust and hurt everyone."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Right. And the industry mostly gets this. They'd rather have clear rules now than face a backlash later."
        },
        {
          "speaker": "A",
          "text": "Building on that, Alright, we'll keep tracking this story. Make sure to follow us for updates as the implementation details come out!"
        },
        {
          "speaker": "A",
          "text": "Let's explore another important aspect of this."
        },
        {
          "speaker": "A",
          "text": "Let's talk about what this AI regulation actually means in practice."
        },
        {
          "speaker": "B",
          "text": "Right, because the devil is in the details. These aren't just guidelines—they're enforceable requirements with real teeth."
        },
        {
          "speaker": "A",
          "text": "So what are the specific requirements?"
        },
        {
          "speaker": "B",
          "text": "Three main categories. First, transparency—companies must disclose how their models work, what data they use, and what their limitations are."
        },
        {
          "speaker": "A",
          "text": "That's a big change. A lot of this has been proprietary until now."
        },
        {
          "speaker": "B",
          "text": "Exactly. Second requirement is regular safety audits. Independent third parties will test these systems for bias, accuracy, and potential harms."
        },
        {
          "speaker": "A",
          "text": "How often?"
        },
        {
          "speaker": "B",
          "text": "Annually for most companies, quarterly for high-risk applications like healthcare or financial services."
        },
        {
          "speaker": "A",
          "text": "That's intensive. And expensive."
        },
        {
          "speaker": "B",
          "text": "Very. Which is why smaller companies are concerned. But it's also necessary—we've seen too many incidents of AI systems going wrong."
        },
        {
          "speaker": "A",
          "text": "What about enforcement? Who's making sure companies comply?"
        },
        {
          "speaker": "B",
          "text": "The Tech Policy Institute gets enforcement powers. They can issue fines up to 4% of global revenue for serious violations."
        },
        {
          "speaker": "A",
          "text": "Wow, that's significant."
        },
        {
          "speaker": "B",
          "text": "It's modeled after GDPR's enforcement structure, which has been pretty effective in Europe."
        },
        {
          "speaker": "A",
          "text": "So what does this mean for innovation? Are we going to see a slowdown?"
        },
        {
          "speaker": "B",
          "text": "Not necessarily. In fact, some argue this could accelerate responsible innovation. When everyone's playing by the same rules, it creates a level playing field."
        },
        {
          "speaker": "A",
          "text": "That's an interesting perspective."
        },
        {
          "speaker": "B",
          "text": "Yeah, and historically, we've seen that regulation can actually increase consumer trust, which grows the market overall."
        },
        {
          "speaker": "A",
          "text": "So it's not just about restrictions—it's about building sustainable growth."
        },
        {
          "speaker": "B",
          "text": "Exactly. The goal is to prevent a major AI disaster that would tank public trust and hurt everyone."
        },
        {
          "speaker": "A",
          "text": "That makes sense. Prevention is better than damage control."
        },
        {
          "speaker": "B",
          "text": "Right. And the industry mostly gets this. They'd rather have clear rules now than face a backlash later."
        },
        {
          "speaker": "A",
          "text": "Alright, we'll keep tracking this story. Make sure to follow us for updates as the implementation details come out! [WORD_COUNT=380]"
        },
        {
          "speaker": "A",
          "text": "Let's dive even deeper into this topic, because there's so much more to explore here."
        },
        {
          "speaker": "B",
          "text": "Absolutely. We've covered the basics, but the implications and details are really worth examining more closely."
        },
        {
          "speaker": "A",
          "text": "Building on that, Let's talk about what this AI regulation actually means in practice."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Right, because the devil is in the details. These aren't just guidelines—they're enforceable requirements with real teeth."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Three main categories. First, transparency—companies must disclose how their models work, what data they use, and what their limitations are."
        },
        {
          "speaker": "A",
          "text": "Building on that, That's a big change. A lot of this has been proprietary until now."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Exactly. Second requirement is regular safety audits. Independent third parties will test these systems for bias, accuracy, and potential harms."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Annually for most companies, quarterly for high-risk applications like healthcare or financial services."
        },
        {
          "speaker": "B",
          "text": "To elaborate, Very. Which is why smaller companies are concerned. But it's also necessary—we've seen too many incidents of AI systems going wrong."
        },
        {
          "speaker": "B",
          "text": "To elaborate, The Tech Policy Institute gets enforcement powers. They can issue fines up to 4% of global revenue for serious violations."
        },
        {
          "speaker": "B",
          "text": "To elaborate, It's modeled after GDPR's enforcement structure, which has been pretty effective in Europe."
        },
        {
          "speaker": "A",
          "text": "Building on that, So what does this mean for innovation? Are we going to see a"
        }
      ]
    }
  ],
  "metadata": {
    "generated_at": "2025-12-26T06:08:17.776129",
    "model": "gpt-5-mini",
    "num_sources": 0,
    "content_type": "medium",
    "content_code": "M2"
  }
}