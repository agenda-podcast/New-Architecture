"""Captions subflow: detect subtitle files and burn them into a video.

This module is intentionally decoupled from the core renderer so captions can be
treated as an independent, reusable feature.

Design goals
..."""

from __future__ import annotations

import os
import re
import subprocess
from pathlib import Path
from typing import Optional, Tuple


def find_caption_file(audio_path: Path, video_path: Path) -> Optional[Path]:
    """Locate a captions file generated by the pipeline.

    We support the convention:
      <stem>.captions.srt
    where stem matches either the audio or video stem (without .script suffix).
    """
    candidates = []
    # Prefer captions near the output video.
    candidates.append(video_path.with_suffix('.captions.srt'))
    # Also check near the audio.
    candidates.append(audio_path.with_suffix('.captions.srt'))

    # Some pipelines generate captions alongside the audio but video stem differs.
    # Try to normalize ".script" suffix.
    if audio_path.stem.endswith('.script'):
        candidates.append(audio_path.with_name(audio_path.stem[:-len('.script')] + '.captions.srt'))
    if video_path.stem.endswith('.script'):
        candidates.append(video_path.with_name(video_path.stem[:-len('.script')] + '.captions.srt'))

    for c in candidates:
        try:
            if c.exists() and c.stat().st_size > 0:
                return c
        except Exception:
            continue
    return None


def _escape_subtitles_path(p: Path) -> str:
    """Escape a path for use inside ffmpeg filter args."""
    # subtitles filter uses ':' as option separator; escape it.
    s = str(p)
    s = s.replace('\\', '\\\\')
    s = s.replace(':', '\\:')
    s = s.replace("'", "\\'")
    return s


def _probe_video_resolution(video_path: Path) -> Tuple[int, int]:
    """Return (width,height) using ffprobe; falls back to (0,0) on failure."""
    try:
        cmd = [
            'ffprobe', '-v', 'error',
            '-select_streams', 'v:0',
            '-show_entries', 'stream=width,height',
            '-of', 'csv=p=0:s=x',
            str(video_path),
        ]
        res = subprocess.run(cmd, capture_output=True, text=True, check=False)
        if res.returncode == 0 and res.stdout.strip():
            w_str, h_str = res.stdout.strip().split('x')
            return int(w_str), int(h_str)
    except Exception:
        pass
    return 0, 0


def _probe_video_duration(video_path: Path) -> float:
    """Return duration in seconds (0.0 on failure)."""
    try:
        cmd = [
            'ffprobe', '-v', 'error',
            '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1',
            str(video_path),
        ]
        res = subprocess.run(cmd, capture_output=True, text=True, check=False)
        if res.returncode == 0 and res.stdout.strip():
            return float(res.stdout.strip())
    except Exception:
        pass
    return 0.0


def _parse_srt_events(srt_path: Path):
    """Parse a minimal subset of SRT. Returns list of (start_s, end_s, text)."""
    def _ts_to_seconds(ts: str) -> float:
        # 00:00:12,345
        hh, mm, rest = ts.split(':', 2)
        ss, ms = rest.split(',', 1)
        return int(hh) * 3600 + int(mm) * 60 + int(ss) + int(ms) / 1000.0

    raw = srt_path.read_text(encoding='utf-8', errors='replace')
    # Normalize newlines
    raw = raw.replace('\r\n', '\n').replace('\r', '\n')
    blocks = [b.strip() for b in raw.split('\n\n') if b.strip()]
    events = []
    for b in blocks:
        lines = [ln.strip('\ufeff') for ln in b.split('\n')]
        if len(lines) < 2:
            continue
        # Optional numeric index in first line
        time_line = lines[1] if '-->' in lines[1] else lines[0]
        if '-->' not in time_line:
            continue
        try:
            a, bts = [x.strip() for x in time_line.split('-->')]
            start_s = _ts_to_seconds(a)
            end_s = _ts_to_seconds(bts.split()[0])
            text_lines = lines[2:] if '-->' in lines[1] else lines[1+1:]
            text_val = '\n'.join([t for t in text_lines if t is not None]).strip()
            # Strip common markup
            text_val = re.sub(r'<[^>]+>', '', text_val).strip()
            if end_s > start_s:
                events.append((start_s, end_s, text_val))
        except Exception:
            continue
    return events


def _validate_srt_against_video(srt_path: Path, video_path: Path) -> Tuple[bool, Optional[float]]:
    """Ensure SRT has at least one non-empty cue overlapping the video timeline.
    Returns (ok, sample_time_s) where sample_time_s is a good timestamp for preview/debug.
    """
    dur = _probe_video_duration(video_path)
    if dur <= 0.0:
        # If we cannot probe duration, we only validate non-empty text
        dur = None

    events = _parse_srt_events(srt_path)
    # Keep only non-empty text events
    events = [(s, e, t) for (s, e, t) in events if t and t.strip()]
    if not events:
        return False, None

    if dur is None:
        # Use midpoint of first event for sampling
        s, e, _ = events[0]
        return True, max(0.0, (s + e) / 2.0)

    # Find first event that overlaps [0, dur]
    for s, e, _ in events:
        if e <= 0.0:
            continue
        if s >= dur:
            continue
        # Overlap exists
        mid = min(dur - 0.05, max(0.0, (max(0.0, s) + min(dur, e)) / 2.0))
        return True, mid

    return False, None


def _force_style_for(style_name: str, width: int, height: int) -> str:
    """Return a libass force_style string.

    Important: when burning an SRT with FFmpeg's `subtitles` filter, libass commonly
    defaults to PlayResY=288 unless the subtitle file explicitly sets a script
    resolution (ASS/SSA). That means *pixel* values for FontSize/Margins must be
    scaled down, otherwise text can render off-screen (invisible).

    We therefore compute a pixel-intended style for 1080x1920 and then scale it to
    libass units using (288 / height).
    """
    if height <= 0:
        height = 1920

    # libass default script resolution (typical when input is SRT)
    play_res_y = int(os.environ.get("LIBASS_PLAYRESY", "288") or "288")
    scale = float(play_res_y) / float(height)

    def _ass(v_px: float, v_min: int = 1, v_max: int | None = None) -> int:
        v = int(round(float(v_px) * scale))
        if v_max is not None:
            v = min(v, int(v_max))
        return max(int(v_min), v)

    # Pixel-intended sizing tuned for 1080x1920.
    px_font = max(54, int(round(height * 0.036)))      # ~69 for 1920
    px_margin_v = max(120, int(round(height * 0.18)))  # ~346 for 1920
    px_outline = max(4, int(round(px_font * 0.16)))    # ~11 for 69px
    px_shadow = max(1, int(round(px_outline * 0.35)))  # subtle

    font_size = _ass(px_font, v_min=8, v_max=26)
    margin_v = _ass(px_margin_v, v_min=12, v_max=80)
    outline = _ass(px_outline, v_min=1, v_max=6)
    shadow = _ass(px_shadow, v_min=0, v_max=4)

    # TikTok-inspired: bold, large, strong outline + subtle shadow.
    if style_name.lower() in ('tiktok', 'social', 'reels'):
        return (
            f"FontName=DejaVu Sans,"
            f"FontSize={font_size},"
            "Bold=1,"
            # &HAABBGGRR& (AA=00 is opaque)
            "PrimaryColour=&H00FFFFFF&,"
            "OutlineColour=&H00000000&,"
            "BackColour=&H00000000&,"
            "BorderStyle=1,"
            f"Outline={outline},"
            f"Shadow={shadow},"
            "Alignment=2,"
            f"MarginV={margin_v}"
        )

    if style_name.lower() in ('minimal', 'clean'):
        return (
            f"FontName=DejaVu Sans,"
            f"FontSize={max(8, font_size - 2)},"
            "Bold=1,"
            "PrimaryColour=&H00FFFFFF&,"
            "OutlineColour=&H00000000&,"
            "BorderStyle=1,"
            f"Outline={max(1, outline - 1)},"
            f"Shadow={max(0, shadow - 1)},"
            "Alignment=2,"
            f"MarginV={max(8, margin_v - 6)}"
        )

    # Default to TikTok.
    return _force_style_for('tiktok', width, height)


def burn_captions(
    video_in: Path,
    captions_srt: Path,
    video_out: Path,
    style_name: str = 'tiktok',
) -> bool:
    """Burn captions into the video.

    Uses libass `subtitles` filter.
    """
    w, h = _probe_video_resolution(video_in)
    force_style = _force_style_for(style_name, w, h)
    subtitles_arg = f"subtitles='{_escape_subtitles_path(captions_srt)}':force_style='{force_style}'"

    # Use fast preset by default; captions burn is an extra encode step.
    preset = os.environ.get('CAPTIONS_PRESET', os.environ.get('FFMPEG_PRESET', 'veryfast')).strip()
    crf = os.environ.get('CAPTIONS_CRF', os.environ.get('FFMPEG_CRF', '23')).strip() or '23'

    cmd = [
        'ffmpeg', '-y',
        '-i', str(video_in),
        '-vf', subtitles_arg,
        '-c:v', 'libx264',
        '-preset', preset,
        '-crf', crf,
        '-pix_fmt', 'yuv420p',
        '-c:a', 'copy',
        '-movflags', '+faststart',
        str(video_out),
    ]

    res = subprocess.run(cmd, capture_output=True, text=True)
    if res.returncode != 0:
        # Surface a concise error for workflow logs.
        err = (res.stderr or '').strip().splitlines()[-12:]
        print("  ⚠ Captions burn-in failed:")
        for line in err:
            print(f"    {line}")
        return False
    return True


def maybe_burn_captions(
    audio_path: Path,
    video_path: Path,
    style_name: Optional[str] = None,
) -> bool:
    """Detect captions and burn them in-place (writes a new file then replaces)."""
    captions = find_caption_file(audio_path, video_path)
    if not captions:
        print("  ⓘ No captions file found; skipping burn-in")
        return True

    style = (style_name or os.environ.get('CAPTIONS_STYLE', 'tiktok')).strip()
    print(f"  Captions detected: {captions.name} (style={style})")

    ok_srt, sample_t = _validate_srt_against_video(captions, video_path)
    if not ok_srt:
        print("  ⚠ Captions file has no visible cues within video timeline; skipping burn")
        require = os.environ.get('REQUIRE_BURNED_CAPTIONS', 'true').strip().lower() in ('1', 'true', 'yes', 'on')
        if require:
            print("  ✗ REQUIRE_BURNED_CAPTIONS is enabled; failing")
            return False
        return True


    tmp_out = video_path.with_name(video_path.stem + '.captions.mp4')
    ok = burn_captions(video_path, captions, tmp_out, style_name=style)
    if not ok:
        require = os.environ.get('REQUIRE_BURNED_CAPTIONS', 'true').strip().lower() in ('1', 'true', 'yes', 'on')
        if require:
            print("  ✗ Captions burn-in failed and REQUIRE_BURNED_CAPTIONS is enabled")
            return False
        print("  ⚠ Captions burn-in failed; continuing without burned captions")
        return True

    # Replace output atomically.
    try:
        tmp_out.replace(video_path)
        print("  ✓ Captions burned into output video")
        if os.environ.get('CAPTIONS_DEBUG_FRAME', 'false').strip().lower() in ('1','true','yes','on') and sample_t is not None:
            try:
                dbg = video_path.with_name(video_path.stem + '.captions_debug.jpg')
                subprocess.run(['ffmpeg','-y','-hide_banner','-loglevel','error','-ss', str(sample_t), '-i', str(video_path), '-vframes','1', str(dbg)], check=False)
                if dbg.exists():
                    print(f"  ⓘ Captions debug frame: {dbg.name} @ {sample_t:.2f}s")
            except Exception:
                pass

        return True
    except Exception as e:
        print(f"  ⚠ Captions burn-in succeeded but replace failed: {e}")
        return False
